<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine-Learning | Haihao Sun&#39;s Homepage</title>
    <link>http://localhost:1313/tags/machine-learning/</link>
      <atom:link href="http://localhost:1313/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Machine-Learning</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Fri, 06 Sep 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu68170e94a17a2a43d6dcb45cf0e8e589_3079_512x512_fill_lanczos_center_3.png</url>
      <title>Machine-Learning</title>
      <link>http://localhost:1313/tags/machine-learning/</link>
    </image>
    
    <item>
      <title>Recommender System Study Notes - Nomination(6/6)</title>
      <link>http://localhost:1313/post/2024-09-06-rec-sys-nomination-6/</link>
      <pubDate>Fri, 06 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024-09-06-rec-sys-nomination-6/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;GeoHash Nomination&lt;/li&gt;
&lt;li&gt;Author Nomination
&lt;ul&gt;
&lt;li&gt;Subscribed Author&lt;/li&gt;
&lt;li&gt;Interacted Author&lt;/li&gt;
&lt;li&gt;Similar Author&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cache Nomination&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;geohash-nomination&#34;&gt;GeoHash Nomination&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Indexing
&lt;ul&gt;
&lt;li&gt;GeoHash -&amp;gt; Item with good quality(reverse chronological order)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;No personalized&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;subscribed-author-nomination&#34;&gt;Subscribed Author Nomination&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Indexing:
&lt;ul&gt;
&lt;li&gt;User -&amp;gt; subscribed authors&lt;/li&gt;
&lt;li&gt;author -&amp;gt; uploaded items&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Nomination:
&lt;ul&gt;
&lt;li&gt;User -&amp;gt; Subscribed Author -&amp;gt; New Item&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;interacted-author-nomination&#34;&gt;Interacted Author Nomination&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;If someone likes/love/forward an item&lt;/li&gt;
&lt;li&gt;Indexing:
&lt;ul&gt;
&lt;li&gt;User -&amp;gt; Interacted Author (update it)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Nomination:
&lt;ul&gt;
&lt;li&gt;User -&amp;gt; Interacted Author -&amp;gt; New Item&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;similar-author-nomination&#34;&gt;Similar Author Nomination&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Indexing:
&lt;ul&gt;
&lt;li&gt;Author -&amp;gt; Similar Author&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Nomination:
&lt;ul&gt;
&lt;li&gt;User ID -&amp;gt; Liked Author -&amp;gt; Similar Author -&amp;gt; New Item&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cache-nomination&#34;&gt;Cache Nomination&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Intuition: Use the previous ranking winning candidates discarded by re-ranking.&lt;/li&gt;
&lt;li&gt;Top 50 items, but get discarded by re-ranking, go to nomination.&lt;/li&gt;
&lt;li&gt;Cache is fixed. How to clear the cache
&lt;ul&gt;
&lt;li&gt;Got impressed&lt;/li&gt;
&lt;li&gt;At most 10 times&lt;/li&gt;
&lt;li&gt;At most 3 days&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bloom-filter&#34;&gt;Bloom Filter&lt;/h3&gt;
&lt;h4 id=&#34;intuition&#34;&gt;Intuition&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;If user has seen an item, then we do not recommend this item to user&lt;/li&gt;
&lt;li&gt;For each user, record item that has been recommended(maybe for a month)&lt;/li&gt;
&lt;li&gt;For each item, check if it&amp;rsquo;s been recommended before&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;basics&#34;&gt;Basics&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;The Bloom filter determines whether an item ID is in the set of exposed items.&lt;/li&gt;
&lt;li&gt;If the judgment is &amp;ldquo;no&amp;rdquo;, then the item is definitely not in the set.&lt;/li&gt;
&lt;li&gt;If the judgment is &amp;ldquo;yes&amp;rdquo;, then the item is likely in the set. (There may be false positives, where an unexposed item is incorrectly judged as exposed and thus filtered out.)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;heading&#34;&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The size of the exposed item set is \( n \), the dimensionality of the binary vector is \( m \), and \( k \) hash functions are used.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The false positive probability of the Bloom filter \( \delta \) is approximately:&lt;/p&gt;
\[
  \delta \approx \left( 1 - \exp\left( \frac{-kn}{m} \right) \right)^k
  \]
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As \( n \) increases, the more 1&amp;rsquo;s there are in the vector, and the higher the false positive probability. (The probability that all \( k \) positions corresponding to unexposed items are set to 1 increases.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As \( m \) increases, the vector becomes longer, making hash collisions less likely.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If \( k \) is too large or too small, it is not ideal; \( k \) has an optimal value.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Exposed Filtering Path:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;               +-------------+              +---------+              +-------------+
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;               |   Recall 1  |------------&amp;gt; | Sorting |------------&amp;gt; |   Item 1    |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;               +-------------+              +---------+              +-------------+
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;               |   Recall 2  |                                                   |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;               +-------------+                                                   |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;               |   Recall 3  |                                                   |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;               +-------------+                                                   v
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                                                           +-------------+
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                                                           |   Item 2    |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                                                           +-------------+
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                                                           |     ...     |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                                                           +-------------+
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                                                           |   Item q    |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                                                           +-------------+
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                      ^                                                        |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                      |                                                        |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;+------------------+  |                                                        |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;| Binary Vector    |&amp;lt;-+                                                        |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;+------------------+                                                           v
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                             +-------------------+     +-----------------------+
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                             | Bloom Filter      |&amp;lt;----| Real-time Processing   |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                             | (Exposure Filter) |     |  (Kafka + Flink)       |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                             +-------------------+     +-----------------------+
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Recommender System Study Notes - Nomination(5/6)</title>
      <link>http://localhost:1313/post/2024-09-05-rec-sys-nomination-5/</link>
      <pubDate>Thu, 05 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024-09-05-rec-sys-nomination-5/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Recommender System Study Notes - Nomination(4/6)</title>
      <link>http://localhost:1313/post/2024-09-04-rec-sys-nomination-4/</link>
      <pubDate>Wed, 04 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024-09-04-rec-sys-nomination-4/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Two tower model full update/incremental update.
&lt;ul&gt;
&lt;li&gt;Online Nomination: Online compute user ID, ANN in stored vector database with item.&lt;/li&gt;
&lt;li&gt;Full Update: 1 epoch, 1 day.&lt;/li&gt;
&lt;li&gt;Incremental Update: Only upadte ID embedding, frozen the fully connected layer.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Two tower model Self-supervised learning
&lt;ul&gt;
&lt;li&gt;Problem: Two tower cannot learn item with limited amount of clicks (data biased).&lt;/li&gt;
&lt;li&gt;Self-supervised learning: random feature transformation&lt;/li&gt;
&lt;li&gt;bi&amp;rsquo;, bi&amp;rsquo;&amp;rsquo; high similarity&lt;/li&gt;
&lt;li&gt;bi&amp;rsquo;, bj&amp;rsquo;&amp;rsquo; low similarity&lt;/li&gt;
&lt;li&gt;Training:
&lt;ul&gt;
&lt;li&gt;pick n (user - item) as a batch for training.&lt;/li&gt;
&lt;li&gt;m items as a batch(uniform sampling) for self-supervised learning.&lt;/li&gt;
&lt;li&gt;$\frac{1}{n} \sum_{i=1}^{n} L_{\text{main}}[i] + \alpha \cdot \frac{1}{m} \sum_{j=1}^{m} L_{\text{self}}[j]$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;online-nomination&#34;&gt;Online Nomination&lt;/h3&gt;
&lt;h4 id=&#34;implementation&#34;&gt;Implementation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Item
&lt;ul&gt;
&lt;li&gt;Use neural network to compute item b&amp;rsquo;s embedding.&lt;/li&gt;
&lt;li&gt;Store them in vectorized databse (Milvus, Faiss, HnswLib).&lt;/li&gt;
&lt;li&gt;Indexing, for ANN search.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;User
&lt;ul&gt;
&lt;li&gt;Use user ID, feature, etc to compute user a&amp;rsquo;s embedding.&lt;/li&gt;
&lt;li&gt;ANN search
&lt;ul&gt;
&lt;li&gt;Use a as query.&lt;/li&gt;
&lt;li&gt;Return the top k as return.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Why store item but compute user online?
&lt;ul&gt;
&lt;li&gt;User is only 1, item is O(b).&lt;/li&gt;
&lt;li&gt;User often changes quickly.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;model-update&#34;&gt;Model Update&lt;/h3&gt;
&lt;h4 id=&#34;full-update-vs-incremental-update&#34;&gt;Full Update VS Incremental Update&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Full Update
&lt;ul&gt;
&lt;li&gt;Use yesterday&amp;rsquo;s tfrecord, train 1 epoch.&lt;/li&gt;
&lt;li&gt;Update the new user neural network, store item data into database.&lt;/li&gt;
&lt;li&gt;Easy to implement, easy requirement for the system.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Incremental Update(online learning)
&lt;ul&gt;
&lt;li&gt;Why? User&amp;rsquo;s interest can change quickly.&lt;/li&gt;
&lt;li&gt;Data streaming, TFRecord.&lt;/li&gt;
&lt;li&gt;Online learning, gradient descent, only update ID Embedding, not other parameters in the neural network.&lt;/li&gt;
&lt;li&gt;Update the new ID embedding.&lt;/li&gt;
&lt;li&gt;To be discarded after full update.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Why only incremental update is not having the best result?
&lt;ul&gt;
&lt;li&gt;Hourly data is biased.&lt;/li&gt;
&lt;li&gt;Full update: random shuffle, 1 epoch.&lt;/li&gt;
&lt;li&gt;Incremental update: train from morning to night, this is not having the best result.&lt;/li&gt;
&lt;li&gt;random shuffle makes a positive impact on the learning.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;two-tower-model-self-supervised-learning&#34;&gt;Two tower model Self-supervised learning&lt;/h3&gt;
&lt;h4 id=&#34;problem&#34;&gt;Problem&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The head effect in the recommendation system is severe:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A small number of items account for most of the clicks.&lt;/li&gt;
&lt;li&gt;Most items have a low number of clicks.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The features of high-click items are well-learned, but the features of long-tail items are not well-learned.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Self-supervised learning: data augumentation, to better learn long-tail items&amp;rsquo; embedding.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;intuition&#34;&gt;Intuition&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;A simple feature transformation will make minimal impact on their feature embeddings, and pairwise, the similarity still remains large.&lt;/li&gt;
&lt;li&gt;i -&amp;gt; i&amp;rsquo; -&amp;gt; bi&amp;rsquo;, i -&amp;gt; i&amp;rsquo;&amp;rsquo; -&amp;gt; bi&amp;rsquo;&amp;rsquo;, j -&amp;gt; j&amp;rsquo; -&amp;gt; bj&amp;rsquo;, j -&amp;gt; j&amp;rsquo;&amp;rsquo;-&amp;gt;bj&#39;&#39;&lt;/li&gt;
&lt;li&gt;i, bi&amp;rsquo; and bi&amp;rsquo;&amp;rsquo; has high similarity&lt;/li&gt;
&lt;li&gt;i, j, bi&amp;rsquo; and bj&amp;rsquo;&amp;rsquo; has low similarity&lt;/li&gt;
&lt;li&gt;cos(bi, bi&amp;rsquo;&amp;rsquo;) big, cos(bi&amp;rsquo;, bj&amp;rsquo;) small&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;methods&#34;&gt;Methods&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Random Mask&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Randomly pick labels, and set them to null.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Dropout&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Randomly dropout 50% label.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Complementary&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;ID, Label, Keywords, City.&lt;/li&gt;
&lt;li&gt;Randomly divide them into two {ID, keyword} and {Label, City}.&lt;/li&gt;
&lt;li&gt;{ID, default, Keyword, default} -&amp;gt; Item embedding.&lt;/li&gt;
&lt;li&gt;{default, Label, default, City} -&amp;gt; Item embedding.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;Mask a set of correlated features&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;U = {Male, Female, Unisex}.&lt;/li&gt;
&lt;li&gt;V = {Photography, Football, IT, Makeup}.&lt;/li&gt;
&lt;li&gt;u = female, v = Makeup, p(u, v) is high.&lt;/li&gt;
&lt;li&gt;u = female, v = IT, p(u, v) is low.&lt;/li&gt;
&lt;li&gt;$MI(U, V) = \sum_{u \in U} \sum_{v \in V} p(u, v) \cdot \log \frac{p(u, v)}{p(u) \cdot p(v)}$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Learning:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Assume there are a total of \( k \) features. Calculate the MI (Mutual Information) between any two features offline, resulting in a \( k \times k \) matrix.&lt;/li&gt;
&lt;li&gt;Randomly select one feature as a seed and find the \( k/2 \) features most related to the seed.&lt;/li&gt;
&lt;li&gt;Mask the seed and its related \( k/2 \) features, retaining the remaining \( k/2 \) features.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Training:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sampling m items as a batch&lt;/li&gt;
&lt;li&gt;cos(bi&amp;rsquo;, bi&amp;rsquo;&amp;rsquo;) -&amp;gt; 1, other cos(bi&amp;rsquo;, bj&amp;rsquo;&amp;rsquo;) -&amp;gt; 0&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Recommender System Study Notes - Nomination(3/6)</title>
      <link>http://localhost:1313/post/2024-09-03-rec-sys-nomination-3/</link>
      <pubDate>Tue, 03 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024-09-03-rec-sys-nomination-3/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Two Tower Model - Architecture + Training&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pointwise Training
&lt;ul&gt;
&lt;li&gt;View nomination as binary classification&lt;/li&gt;
&lt;li&gt;Sample: cos(a,b) -&amp;gt; +1, negative sample: cos(a, b) -&amp;gt; -1&lt;/li&gt;
&lt;li&gt;Positive : negative = 1:2 / 1:3&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pairwise Training
&lt;ul&gt;
&lt;li&gt;Intuntion: cos(a, b+) &amp;gt; cos(a, b-)&lt;/li&gt;
&lt;li&gt;Triplet hinge loss = max(0, cos(a, b-) + m - cos(a, b+))&lt;/li&gt;
&lt;li&gt;Triplet logistic loss = log(1 + exp(σ) * cos(a, b-) - cos(a, b+))&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Listwise Training
&lt;ul&gt;
&lt;li&gt;CrossEntropyLoss&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Two Tower Model - Positive Samples + Negative Samples&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Positive Sample:
&lt;ul&gt;
&lt;li&gt;Impressed and clicked&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Negative Sample:&lt;/li&gt;
&lt;li&gt;Easy negative sample:
&lt;ul&gt;
&lt;li&gt;All items&lt;/li&gt;
&lt;li&gt;In-batch items&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hard negative sample:
&lt;ul&gt;
&lt;li&gt;Nominated, but discarded by ranking&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mix easy and hard for training dataset&lt;/li&gt;
&lt;li&gt;Wrong sampling:
&lt;ul&gt;
&lt;li&gt;Impressed, but not clicked (can be used for training ranking but not nomination)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;two-tower-modeldssm---architecture-and-training&#34;&gt;Two Tower Model(DSSM) - Architecture and Training&lt;/h3&gt;
&lt;h4 id=&#34;two-tower-model-architecture&#34;&gt;Two Tower Model Architecture&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Neural Network
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    └── Concatenate
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        ├── Embedding Layer (User ID)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        │      └── Embedding (Vector Representation)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        ├── Embedding Layers (User Discrete Feature)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        │      └── Embedding (Vector Representation)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        └── Normalization, Binning, etc. (normalize to 1, put into buckets)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;               └── User Continuous Features (Vector Representation)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;$\cos(a, b) = \frac{a \cdot b}{\|a\|_2 \cdot \|b\|_2}$&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                            Cosine Similarity:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                  /    \
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                /        \
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                             a            b
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                          /                 \
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              Neural Network              Neural Network
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                /                                \
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         Feature Transformation           Feature Transformation
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         /                                          \
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;User ID, Discrete Features,                 Product ID, Discrete Features,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Continuous Features                         Continuous Features
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;two-tower-model-training&#34;&gt;Two Tower Model Training&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Pointwise (binary classification)&lt;/li&gt;
&lt;li&gt;Pairwise&lt;/li&gt;
&lt;li&gt;Listwise&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;pointwise-training&#34;&gt;Pointwise Training&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Intuition: View nomination as binary classification&lt;/li&gt;
&lt;li&gt;positive sample: cos(a,b) -&amp;gt; +1, negative sample: cos(a, b) -&amp;gt; -1&lt;/li&gt;
&lt;li&gt;positive : negative = 1:2 / 1:3&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;pairwise-training&#34;&gt;Pairwise Training&lt;/h5&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    cos(a, b⁺)          cos(a, b⁻)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    /      \            /      \
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                   /        \          /        \
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                b⁺               a                  b⁻
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        (Positive Sample)       (User)           (Negative Sample)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                |                  |                    |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        Neural Network      Neural Network     Neural Network
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                |                  |                    |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Feature Transformation   Feature Transformation Feature Transformation
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                |                  |                    |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Positive Item Feature     User Features          Negative Item Feature
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Intuntion: cos(a, b+) &amp;gt; cos(a, b-)&lt;/li&gt;
&lt;li&gt;triplet hinge loss = max(0, cos(a, b-) + m - cos(a, b+))&lt;/li&gt;
&lt;li&gt;triplet logistic loss = log(1 + exp(σ) * cos(a, b-) - cos(a, b+))&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;listwise-training&#34;&gt;Listwise Training&lt;/h5&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CrossEntropyLoss(y, s) = -log(s⁺)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                       +-----------------------+
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                       |    CrossEntropyLoss   |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                       +-----------------------+
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                 |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                 |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                          +-------------------------------+
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                          |  Softmax Activation Function  |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                          +-------------------------------+
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                 |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      +------------+------------+-------------+ ... +------------+
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      |            |            |             |     |            |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     s⁺         s⁻_1       s⁻_2         ...   s⁻_n
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; (Positive)    (Negative)  (Negative)        (Negative)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    |             |             |                     |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    |             |             |                     |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; cos(a, b⁺)   cos(a, b⁻_1)  cos(a, b⁻_2)   ...  cos(a, b⁻_n)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   |              |             |                     |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;(Positive)    (Negative)   (Negative)         (Negative)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Sample         Sample        Sample            Sample
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;two-tower-modeldssm---positive-samples--negative-samples&#34;&gt;Two Tower Model(DSSM) - Positive Samples + Negative Samples&lt;/h3&gt;
&lt;h4 id=&#34;positive-samples&#34;&gt;Positive Samples&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;impressed and clicked&lt;/li&gt;
&lt;li&gt;problem: 20% item takes 80% click&lt;/li&gt;
&lt;li&gt;solution:
&lt;ul&gt;
&lt;li&gt;up-sampling: one sample appear multiple times&lt;/li&gt;
&lt;li&gt;down-sampling: discard samples&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;negative-samples&#34;&gt;Negative Samples&lt;/h4&gt;
&lt;h5 id=&#34;simple-negative-sampling-all-items&#34;&gt;Simple Negative Sampling: All Items&lt;/h5&gt;
&lt;h6 id=&#34;uniform-sampling-unfair-to-unpopular-items&#34;&gt;Uniform Sampling: Unfair to unpopular items&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;Most positive samples are popular items.&lt;/li&gt;
&lt;li&gt;If uniform sampling produces negative samples, most of the negative samples are unpopular items.&lt;/li&gt;
&lt;li&gt;positive sample: popular items, negative sample: unpopular items, this is unfair.&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;non-uniform-sampling-the-goal-is-to-suppress-popular-items&#34;&gt;Non-uniform Sampling: The goal is to suppress popular items&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;The probability of negative sampling is positively correlated with popularity (clicks).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sampling probability ∝ (clicks) ^ 0.75&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;simple-negative-sampling-negative-sample-within-a-batch&#34;&gt;Simple Negative Sampling: Negative Sample within a batch&lt;/h5&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user1 - item1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user2 - item2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user3 - item3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user_n - item_n
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;one batch has n positive samples&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;one batch has n(n - 1) negative samples&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The probablity that an item appear in a batch is propotional to the number of times it clicked.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We aim to get it propotional to clicks^0.75.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;offline training cos(a, bi) - log(pi), pi ∝ clicks&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;online inference cos(a, bi)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;hard-negative-sampling&#34;&gt;Hard Negative Sampling&lt;/h4&gt;
&lt;h5 id=&#34;hard-negative-samples&#34;&gt;Hard negative samples:&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Items that are ranked and close to the target (relatively hard).&lt;/li&gt;
&lt;li&gt;Items that are ranked far behind the target (extremely hard).&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;binary-classification-for-positive-and-negative-samples&#34;&gt;Binary classification for positive and negative samples:&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;All items (simple): High classification accuracy.&lt;/li&gt;
&lt;li&gt;Items that are ranked and close to the target (relatively hard): Easy to misclassify.&lt;/li&gt;
&lt;li&gt;Items that are ranked far behind the target (extremely hard): Even easier to misclassify.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;datasets&#34;&gt;Datasets&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Mix negative samples&lt;/li&gt;
&lt;li&gt;50% easy negative sample&lt;/li&gt;
&lt;li&gt;50% hard negative sample&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Recommender System Study Notes - Nomination(2/6)</title>
      <link>http://localhost:1313/post/2024-09-03-rec-sys-nomination-2/</link>
      <pubDate>Mon, 02 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024-09-03-rec-sys-nomination-2/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Discrete Feature&lt;/li&gt;
&lt;li&gt;Matrix Completion&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;discrete-feature&#34;&gt;Discrete Feature&lt;/h3&gt;
&lt;h4 id=&#34;example&#34;&gt;Example&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;sex&lt;/li&gt;
&lt;li&gt;nationality&lt;/li&gt;
&lt;li&gt;english words&lt;/li&gt;
&lt;li&gt;item id&lt;/li&gt;
&lt;li&gt;user id&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;how-to-encode-discrete-feature---vectorization&#34;&gt;How to encode discrete feature -&amp;gt; vectorization&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;one-hot encoding&lt;/li&gt;
&lt;li&gt;embedding (*)
&lt;ul&gt;
&lt;li&gt;size: vector dimension * number of items&lt;/li&gt;
&lt;li&gt;How to implement: TensorFlow, PyTorch -&amp;gt; embedding&lt;/li&gt;
&lt;li&gt;embedding = Parameter matrix * one-hot encoding&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;matrix-completion&#34;&gt;Matrix Completion&lt;/h3&gt;
&lt;h4 id=&#34;intuition&#34;&gt;Intuition&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;item id -&amp;gt; embedding
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    \
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                     - cos(a, b)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    /
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;item id -&amp;gt; embedding
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;formula&#34;&gt;Formula&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;dataset = {u, i, y}&lt;/li&gt;
&lt;li&gt;training, u -&amp;gt; au, i -&amp;gt; bi&lt;/li&gt;
&lt;li&gt;optimization: $\min_{A, B} \sum_{\substack{(u, i, y) \in \Omega}} \left( y - \langle a_u, b_i \rangle \right)^2$&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;proscons&#34;&gt;Pros/Cons&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Cons
&lt;ul&gt;
&lt;li&gt;It only uses ID embedding without item, user characteristics
&lt;ul&gt;
&lt;li&gt;item characteristics: label, key words&lt;/li&gt;
&lt;li&gt;user characteristics: gender, age, geo, liked label&lt;/li&gt;
&lt;li&gt;Two tower Model&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Negative sample is wrong
&lt;ul&gt;
&lt;li&gt;Positive: User interacted, which is good&lt;/li&gt;
&lt;li&gt;Negative: User did not interact, which is not correct&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Training
&lt;ul&gt;
&lt;li&gt;dot product is worse than cosine similarity&lt;/li&gt;
&lt;li&gt;Loss(regression) is worse than cross entropy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;implementation&#34;&gt;Implementation&lt;/h4&gt;
&lt;h5 id=&#34;offline&#34;&gt;Offline:&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Learning A: user&lt;/li&gt;
&lt;li&gt;Learning B: item&lt;/li&gt;
&lt;li&gt;storing A into {user id: embedding} key-value&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;online&#34;&gt;Online:&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;user Id -&amp;gt; find a&amp;rsquo;s vector&lt;/li&gt;
&lt;li&gt;nearest neighbour search, return the top 100 b whose &amp;lt;a, b&amp;gt; is max&lt;/li&gt;
&lt;li&gt;Approximate Nearest Neighbor (ANN)
&lt;ul&gt;
&lt;li&gt;pre process the circile into sectors&lt;/li&gt;
&lt;li&gt;pick a representative vector(indexing) represents the sector&lt;/li&gt;
&lt;li&gt;find representative vector, then find vector in that sector instead of the whole circle&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Recommender System Study Notes - Nomination(1/6)</title>
      <link>http://localhost:1313/post/2024-09-02-rec-sys-nomination-1/</link>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024-09-02-rec-sys-nomination-1/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Item CF&lt;/li&gt;
&lt;li&gt;Swing&lt;/li&gt;
&lt;li&gt;User CF&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;item-cf&#34;&gt;Item CF&lt;/h3&gt;
&lt;h4 id=&#34;intuition&#34;&gt;Intuition&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;If user likes i1 and i1 is similar with i2 -&amp;gt; Then user is likely to like i2&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;formula&#34;&gt;Formula&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;$score = \sum_j \text{like}(\text{user}, \text{item}\_j) \times \text{sim}(\text{item}\_j, \text{item})$, to compute Item CF score&lt;/li&gt;
&lt;li&gt;$\text{sim}(i_1, i_2) = \frac{|\mathbf{v}|}{\sqrt{|\mathbf{w}_1| \cdot |\mathbf{w}_2|}}$, to compute similarity, w1 as the user who likes i1, w2 as the set, v as the intersection between i1 and i2.&lt;/li&gt;
&lt;li&gt;$\text{sim}(i*1, i_2) = \frac{\sum*{v \in v} \text{like}(v, i*1) \cdot \text{like}(v, i_2)}{\sqrt{\sum*{u*1 \in w_1} \text{like}^2(u_1, i_1)} \cdot \sqrt{\sum*{u_2 \in w_2} \text{like}^2(u_2, i_2)}}$, to take like score into consideration).&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;implementation&#34;&gt;Implementation&lt;/h4&gt;
&lt;h5 id=&#34;offline&#34;&gt;Offline:&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;User -&amp;gt; Item Indexing
&lt;ul&gt;
&lt;li&gt;return the last-n items with interaction that this user interacts with.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Item -&amp;gt; Item Indexing
&lt;ul&gt;
&lt;li&gt;compute sim (i, j) maybe maintaining User-&amp;gt;Item&lt;/li&gt;
&lt;li&gt;for each item, find the cloest k items&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;online-inference-user-id---100-items&#34;&gt;Online Inference: (user id -&amp;gt; 100 items)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;user id -&amp;gt; last-n items&lt;/li&gt;
&lt;li&gt;for each item in last-n, use item-item to find k items&lt;/li&gt;
&lt;li&gt;Use score formula to compute n * k items&amp;rsquo; score&lt;/li&gt;
&lt;li&gt;pick top 100, and output top 100 items as the nomination result in this Item CF Channel&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;swing&#34;&gt;Swing&lt;/h3&gt;
&lt;h4 id=&#34;intuition-1&#34;&gt;Intuition&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;If two items are not that relavant, but it got forwarded into a same small group, we want to lower the similarity score.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;formula-1&#34;&gt;Formula&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;u1 -&amp;gt; j1, u2 -&amp;gt; j2
&lt;ul&gt;
&lt;li&gt;$\text{overlap}(u_1, u_2) = |\mathcal{J}_1 \cap \mathcal{J}_2|$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;i1 -&amp;gt; w1, i2 -&amp;gt; w2, v = w1 ∩ w2
&lt;ul&gt;
&lt;li&gt;$\text{sim}(i_1, i_2) = \sum_{u_1 \in V} \sum_{u_2 \in V} \frac{1}{\alpha + \text{overlap}(u_1, u_2)}$, to compute similarity, a is a hyper-parameter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;if overlap is big, then the contribution to similarity becomes low&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;user-cf&#34;&gt;User CF&lt;/h3&gt;
&lt;h4 id=&#34;intuition-2&#34;&gt;Intuition&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;I will like the notes which liked by someone who is similar to me.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;formula-2&#34;&gt;Formula&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Method1: like, collect, click notes are similar&lt;/li&gt;
&lt;li&gt;Method2: Subscribed authors are similar&lt;/li&gt;
&lt;li&gt;u1 -&amp;gt; j1, u2 -&amp;gt; j2, I = j1 ∩ j2, nl: the number of users who likes l
&lt;ul&gt;
&lt;li&gt;$sim = \text{sim}(u_1, u_2) = \frac{|I|}{\sqrt{|\mathcal{J}_1| \cdot |\mathcal{J}_2|}}$&lt;/li&gt;
&lt;li&gt;$sim = \text{sim}(u_1, u_2) = \frac{\sum_{I \in I} \frac{1}{\log(1 + n_I)}}{\sqrt{|\mathcal{J}_1| \cdot |\mathcal{J}_2|}}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$score = \sum_j \text{sim(user, user}_j\text{)} \times \text{like(user}_j, \text{item)}$&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;implementation-1&#34;&gt;Implementation&lt;/h4&gt;
&lt;h5 id=&#34;offline-1&#34;&gt;Offline:&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;User -&amp;gt; Item Indexing
&lt;ul&gt;
&lt;li&gt;return the last-n items with interaction that this user interacts with.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;User -&amp;gt; User Indexing
&lt;ul&gt;
&lt;li&gt;compute sim (i, j)&lt;/li&gt;
&lt;li&gt;for each user, find the cloest k users&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;online&#34;&gt;Online:&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;user-user indexing: id -&amp;gt; k cloest users&lt;/li&gt;
&lt;li&gt;user-item indexing: for each user, find his/her last-n, use user-item to find n items&lt;/li&gt;
&lt;li&gt;compute score: Use the formula to compute n * k items&amp;rsquo; score&lt;/li&gt;
&lt;li&gt;rank: pick top 100, and output top 100 items as the nomination result in this User CF Channel&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Recommender System Study Notes Basics (1/1)</title>
      <link>http://localhost:1313/post/2024-09-01-rec-sys-basics-1/</link>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024-09-01-rec-sys-basics-1/</guid>
      <description>&lt;h2 id=&#34;basics&#34;&gt;Basics&lt;/h2&gt;
&lt;div class=&#34;markmap&#34; style=&#34;height: 200px;&#34;&gt;

&lt;pre&gt;- Impression
  - Click
    - ScrollToEnd
      - Comment
    - Like
    - Collect
    - Share&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&#34;基础指标&#34;&gt;基础指标&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Click-through rate = Number of clicks / Number of impressions&lt;/li&gt;
&lt;li&gt;Like rate = Number of likes / Number of impressions&lt;/li&gt;
&lt;li&gt;Collection rate = Number of collections / Number of clicks&lt;/li&gt;
&lt;li&gt;Forwarding rate = Number of forwards / Number of clicks&lt;/li&gt;
&lt;li&gt;Completion rate = Number of times scrolled to the end / Number of clicks * f(Note length)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;北极星指标&#34;&gt;北极星指标&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;用户规模
DAU daily active user
MAU monthly active user&lt;/li&gt;
&lt;li&gt;消费
人均使用时长，人均阅读笔记数量&lt;/li&gt;
&lt;li&gt;发布
发布渗透率，人均发布量&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;实验流程&#34;&gt;实验流程&lt;/h4&gt;
&lt;div class=&#34;markmap&#34; style=&#34;height: 200px;&#34;&gt;

&lt;pre&gt;- Offline Test
  - A/B Test
    - experiment rollout&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&#34;chain-of-recommender-system&#34;&gt;Chain of Recommender System&lt;/h4&gt;
&lt;div class=&#34;markmap&#34; style=&#34;height: 200px;&#34;&gt;

&lt;pre&gt;- Nomination
  - Pre-Ranking
    - Ranking
      - Re-Ranking&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Nomination O(billion) -&amp;gt; O(k)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CF&lt;/li&gt;
&lt;li&gt;Two Tower&lt;/li&gt;
&lt;li&gt;Subscribed Content Creator&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pre-Ranking + Ranking O(k) -&amp;gt; O(100)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use a neural network as follow:&lt;/li&gt;
&lt;li&gt;Input:
&lt;ul&gt;
&lt;li&gt;User Feature Embedding&lt;/li&gt;
&lt;li&gt;Item Feature Embedding&lt;/li&gt;
&lt;li&gt;Stats Embedding&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Output:
&lt;ul&gt;
&lt;li&gt;Click-through rate&lt;/li&gt;
&lt;li&gt;Like Rate&lt;/li&gt;
&lt;li&gt;Collection Rate&lt;/li&gt;
&lt;li&gt;Forwarding Rate&lt;/li&gt;
&lt;li&gt;Completion Rate&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Combine them and output a score&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Re-Ranking O(100) -&amp;gt; O(80?) | for diversity&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Common methods:&lt;/li&gt;
&lt;li&gt;MMR&lt;/li&gt;
&lt;li&gt;DPP&lt;/li&gt;
&lt;li&gt;use pre-set rules to diversify notes&lt;/li&gt;
&lt;li&gt;insert ads, change sequence based on rules&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;ab-test&#34;&gt;A/B Test&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Basic flow:
&lt;ul&gt;
&lt;li&gt;new GNN, Offline testing gives promising results&lt;/li&gt;
&lt;li&gt;online A/B test, vaildate&lt;/li&gt;
&lt;li&gt;tune hyper parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;how to put user into buckets randomly
&lt;ul&gt;
&lt;li&gt;hash user id&lt;/li&gt;
&lt;li&gt;compute metrics for each bucket, DAU, etc&lt;/li&gt;
&lt;li&gt;experiment rollout&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Overlapping experiment
&lt;ul&gt;
&lt;li&gt;overlapping: nomination, pre-ranking, ranking, re-ranking, user interface, ads&lt;/li&gt;
&lt;li&gt;each layer: mutually exclusive&lt;/li&gt;
&lt;li&gt;between layers: orthogonality&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Holdout mechanism
&lt;ul&gt;
&lt;li&gt;10% as holdout bucket + 90% as overlapping experiment&lt;/li&gt;
&lt;li&gt;clean holdout and rollout experiment&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Experiment Rollout&lt;/li&gt;
&lt;li&gt;Experiment Reverse&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pre-ranking-rankingscoring&#34;&gt;Pre-Ranking, Ranking(scoring)&lt;/h3&gt;
&lt;h3 id=&#34;re-ranking&#34;&gt;Re-Ranking&lt;/h3&gt;
</description>
    </item>
    
  </channel>
</rss>
